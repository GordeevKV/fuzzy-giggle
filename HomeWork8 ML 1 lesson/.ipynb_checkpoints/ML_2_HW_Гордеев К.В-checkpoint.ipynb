{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Выделение целевой переменной и признаков\n",
    "X = data.drop(columns=['MEDV'])\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Проверка размеров полученных выборок\n",
    "print(\"Размер обучающей выборки:\", X_train.shape)\n",
    "print(\"Размер тестовой выборки:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   task        R2\n",
      "0     LR  task2  0.668483\n",
      "1  Ridge  task2  0.665961\n",
      "2  Lasso  task2  0.666869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Создание и обучение моделей\n",
    "lr_model = LinearRegression()\n",
    "ridge_model = Ridge(random_state=RANDOM_STATE)\n",
    "lasso_model = Lasso(random_state=RANDOM_STATE)\n",
    "\n",
    "# Обучение моделей\n",
    "lr_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Вычисление R² для каждой модели\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты для задания 2 и 3:\n",
      "                model   task        R2\n",
      "0                  LR  task2  0.668483\n",
      "1               Ridge  task2  0.665961\n",
      "2               Lasso  task2  0.666869\n",
      "3  Ridge_GridSearchCV  task3  0.668483\n",
      "4             RidgeCV  task3  0.668483\n",
      "5  Lasso_GridSearchCV  task3  0.668483\n",
      "6             LassoCV  task3  0.668483\n",
      "\n",
      "Сравнение с результатами из задания 2:\n",
      "Ridge (GridSearchCV) улучшение R²: 0.0025\n",
      "Ridge (RidgeCV) улучшение R²: 0.0025\n",
      "Lasso (GridSearchCV) улучшение R²: 0.0016\n",
      "Lasso (LassoCV) улучшение R²: 0.0016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Задание диапазона параметров для регуляризации (по степеням 10)\n",
    "alphas = np.logspace(-5, 5, 100)\n",
    "\n",
    "# GridSearchCV для Ridge\n",
    "ridge_grid_search = GridSearchCV(Ridge(random_state=RANDOM_STATE), \n",
    "                                 param_grid={'alpha': alphas}, \n",
    "                                 cv=5, \n",
    "                                 scoring='r2')\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "r2_ridge_grid_search = r2_score(y_test, ridge_grid_search.predict(X_test))\n",
    "\n",
    "# RidgeCV\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "r2_ridge_cv = r2_score(y_test, ridge_cv.predict(X_test))\n",
    "\n",
    "# GridSearchCV для Lasso\n",
    "lasso_grid_search = GridSearchCV(Lasso(random_state=RANDOM_STATE), \n",
    "                                 param_grid={'alpha': alphas}, \n",
    "                                 cv=5, \n",
    "                                 scoring='r2')\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "r2_lasso_grid_search = r2_score(y_test, lasso_grid_search.predict(X_test))\n",
    "\n",
    "# LassoCV\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "r2_lasso_cv = r2_score(y_test, lasso_cv.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Результаты для задания 2 и 3:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение с результатами из задания 2\n",
    "improvement_ridge_grid_search = r2_ridge_grid_search - results_regression.loc[1, 'R2']\n",
    "improvement_ridge_cv = r2_ridge_cv - results_regression.loc[1, 'R2']\n",
    "improvement_lasso_grid_search = r2_lasso_grid_search - results_regression.loc[2, 'R2']\n",
    "improvement_lasso_cv = r2_lasso_cv - results_regression.loc[2, 'R2']\n",
    "\n",
    "print(\"\\nСравнение с результатами из задания 2:\")\n",
    "print(f\"Ridge (GridSearchCV) улучшение R²: {improvement_ridge_grid_search:.4f}\")\n",
    "print(f\"Ridge (RidgeCV) улучшение R²: {improvement_ridge_cv:.4f}\")\n",
    "print(f\"Lasso (GridSearchCV) улучшение R²: {improvement_lasso_grid_search:.4f}\")\n",
    "print(f\"Lasso (LassoCV) улучшение R²: {improvement_lasso_cv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3 и 4:\n",
      "                   model   task        R2\n",
      "0                     LR  task2  0.668483\n",
      "1                  Ridge  task2  0.665961\n",
      "2                  Lasso  task2  0.666869\n",
      "3     Ridge_GridSearchCV  task3  0.668483\n",
      "4                RidgeCV  task3  0.668483\n",
      "5     Lasso_GridSearchCV  task3  0.668483\n",
      "6                LassoCV  task3  0.668483\n",
      "7   Ridge_StandardScaler  task4  0.668190\n",
      "8     Ridge_MinMaxScaler  task4  0.676221\n",
      "9   Lasso_StandardScaler  task4  0.624045\n",
      "10    Lasso_MinMaxScaler  task4  0.257392\n",
      "\n",
      "Сравнение R² моделей из задания 4 с моделями из заданий 2 и 3:\n",
      "R² Ridge (StandardScaler): 0.6682 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler): 0.6762 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler): 0.6240 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler): 0.2574 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler\n",
    "ridge_standard_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_standard_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler = r2_score(y_test, ridge_standard_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler\n",
    "ridge_minmax_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_minmax_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler = r2_score(y_test, ridge_minmax_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler\n",
    "lasso_standard_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler = r2_score(y_test, lasso_standard_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler\n",
    "lasso_minmax_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler = r2_score(y_test, lasso_minmax_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3 и 4:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 4 с моделями из заданий 2 и 3:\")\n",
    "\n",
    "# Сравнение Ridge с StandardScaler и MinMaxScaler и базовыми результатами\n",
    "print(f\"R² Ridge (StandardScaler): {r2_ridge_standart_scaler:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler): {r2_ridge_min_max_scaler:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение Lasso с StandardScaler и MinMaxScaler и базовыми результатами\n",
    "print(f\"R² Lasso (StandardScaler): {r2_lasso_standart_scaler:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler): {r2_lasso_min_max_scaler:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4 и 5:\n",
      "                      model   task        R2\n",
      "0                        LR  task2  0.668483\n",
      "1                     Ridge  task2  0.665961\n",
      "2                     Lasso  task2  0.666869\n",
      "3        Ridge_GridSearchCV  task3  0.668483\n",
      "4                   RidgeCV  task3  0.668483\n",
      "5        Lasso_GridSearchCV  task3  0.668483\n",
      "6                   LassoCV  task3  0.668483\n",
      "7      Ridge_StandardScaler  task4  0.668190\n",
      "8        Ridge_MinMaxScaler  task4  0.676221\n",
      "9      Lasso_StandardScaler  task4  0.624045\n",
      "10       Lasso_MinMaxScaler  task4  0.257392\n",
      "11  Ridge_StandardScaler_CV  task5  0.667652\n",
      "12    Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13  Lasso_StandardScaler_CV  task5  0.668482\n",
      "14    Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "\n",
      "Сравнение R² моделей из задания 5 с моделями из заданий 2, 3 и 4:\n",
      "R² Ridge (StandardScaler + CV): 0.6677 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + CV): 0.6717 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + CV): 0.6685 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + CV): 0.6685 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "# RidgeCV на данных с StandardScaler\n",
    "ridge_standard_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_standard_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_cv = r2_score(y_test, ridge_standard_cv_pipeline.predict(X_test))\n",
    "\n",
    "# RidgeCV на данных с MinMaxScaler\n",
    "ridge_minmax_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_minmax_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_cv = r2_score(y_test, ridge_minmax_cv_pipeline.predict(X_test))\n",
    "\n",
    "# LassoCV на данных с StandardScaler\n",
    "lasso_standard_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_cv = r2_score(y_test, lasso_standard_cv_pipeline.predict(X_test))\n",
    "\n",
    "# LassoCV на данных с MinMaxScaler\n",
    "lasso_minmax_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_cv = r2_score(y_test, lasso_minmax_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4 и 5:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 5 с моделями из заданий 2, 3 и 4:\")\n",
    "\n",
    "# Сравнение RidgeCV на масштабированных данных с результатами из заданий 2, 3 и 4\n",
    "print(f\"R² Ridge (StandardScaler + CV): {r2_ridge_standart_scaler_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + CV): {r2_ridge_min_max_scaler_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение LassoCV на масштабированных данных с результатами из заданий 2, 3 и 4\n",
    "print(f\"R² Lasso (StandardScaler + CV): {r2_lasso_standart_scaler_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + CV): {r2_lasso_min_max_scaler_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4, 5 и 6:\n",
      "                        model   task        R2\n",
      "0                          LR  task2  0.668483\n",
      "1                       Ridge  task2  0.665961\n",
      "2                       Lasso  task2  0.666869\n",
      "3          Ridge_GridSearchCV  task3  0.668483\n",
      "4                     RidgeCV  task3  0.668483\n",
      "5          Lasso_GridSearchCV  task3  0.668483\n",
      "6                     LassoCV  task3  0.668483\n",
      "7        Ridge_StandardScaler  task4  0.668190\n",
      "8          Ridge_MinMaxScaler  task4  0.676221\n",
      "9        Lasso_StandardScaler  task4  0.624045\n",
      "10         Lasso_MinMaxScaler  task4  0.257392\n",
      "11    Ridge_StandardScaler_CV  task5  0.667652\n",
      "12      Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13    Lasso_StandardScaler_CV  task5  0.668482\n",
      "14      Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15  Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16    Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17  Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18    Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "\n",
      "Сравнение R² моделей из задания 6 с моделями из заданий 2, 3, 4 и 5:\n",
      "R² Ridge (StandardScaler + Poly): 0.8171 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + Poly): 0.8299 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + Poly): 0.7323 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + Poly): 0.2611 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Создание PolynomialFeatures (попарные произведения признаков и их квадраты)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler и PolynomialFeatures\n",
    "ridge_standard_poly_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_standard_poly_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_poly = r2_score(y_test, ridge_standard_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler и PolynomialFeatures\n",
    "ridge_minmax_poly_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_minmax_poly_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_poly = r2_score(y_test, ridge_minmax_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler и PolynomialFeatures\n",
    "lasso_standard_poly_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_poly_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_poly = r2_score(y_test, lasso_standard_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler и PolynomialFeatures\n",
    "lasso_minmax_poly_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_poly_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_poly = r2_score(y_test, lasso_minmax_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4, 5 и 6:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 6 с моделями из заданий 2, 3, 4 и 5:\")\n",
    "\n",
    "# Сравнение Ridge с PolynomialFeatures на данных, прошедших через StandardScaler и MinMaxScaler, с результатами из заданий 2, 3, 4 и 5\n",
    "print(f\"R² Ridge (StandardScaler + Poly): {r2_ridge_standart_scaler_poly:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + Poly): {r2_ridge_min_max_scaler_poly:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение Lasso с PolynomialFeatures на данных, прошедших через StandardScaler и MinMaxScaler, с результатами из заданий 2, 3, 4 и 5\n",
    "print(f\"R² Lasso (StandardScaler + Poly): {r2_lasso_standart_scaler_poly:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + Poly): {r2_lasso_min_max_scaler_poly:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.481217564566123, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.912554424862719, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.65145301711209, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.547071195946501, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4, 5, 6 и 7:\n",
      "                           model   task        R2\n",
      "0                             LR  task2  0.668483\n",
      "1                          Ridge  task2  0.665961\n",
      "2                          Lasso  task2  0.666869\n",
      "3             Ridge_GridSearchCV  task3  0.668483\n",
      "4                        RidgeCV  task3  0.668483\n",
      "5             Lasso_GridSearchCV  task3  0.668483\n",
      "6                        LassoCV  task3  0.668483\n",
      "7           Ridge_StandardScaler  task4  0.668190\n",
      "8             Ridge_MinMaxScaler  task4  0.676221\n",
      "9           Lasso_StandardScaler  task4  0.624045\n",
      "10            Lasso_MinMaxScaler  task4  0.257392\n",
      "11       Ridge_StandardScaler_CV  task5  0.667652\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13       Lasso_StandardScaler_CV  task5  0.668482\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15     Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17     Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.821513\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.849789\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.817555\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.849540\n",
      "\n",
      "Сравнение R² моделей из задания 7 с моделями из заданий 2, 3, 4, 5 и 6:\n",
      "R² Ridge (StandardScaler + Poly + CV): 0.8215 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + Poly + CV): 0.8498 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + Poly + CV): 0.8176 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + Poly + CV): 0.8495 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Альтернативные значения коэффициентов регуляризации\n",
    "alphas = np.logspace(-4, 4, 20)  # Увеличение диапазона для более тщательного поиска\n",
    "\n",
    "# PolynomialFeatures (попарные произведения признаков и их квадраты)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler, PolynomialFeatures и RidgeCV\n",
    "ridge_standard_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_standard_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_poly_cv = r2_score(y_test, ridge_standard_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler, PolynomialFeatures и RidgeCV\n",
    "ridge_minmax_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_minmax_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_poly_cv = r2_score(y_test, ridge_minmax_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler, PolynomialFeatures и LassoCV\n",
    "lasso_standard_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, max_iter=200000, tol=1e-4, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_standard_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_poly_cv = r2_score(y_test, lasso_standard_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler, PolynomialFeatures и LassoCV\n",
    "lasso_minmax_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, max_iter=200000, tol=1e-4, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_minmax_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_poly_cv = r2_score(y_test, lasso_minmax_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4, 5, 6 и 7:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 7 с моделями из заданий 2, 3, 4, 5 и 6:\")\n",
    "\n",
    "# Сравнение RidgeCV с PolynomialFeatures и масштабированием с результатами из заданий 2, 3, 4, 5 и 6\n",
    "print(f\"R² Ridge (StandardScaler + Poly + CV): {r2_ridge_standart_scaler_poly_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + Poly + CV): {r2_ridge_min_max_scaler_poly_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение LassoCV с PolynomialFeatures и масштабированием с результатами из заданий 2, 3, 4, 5 и 6\n",
    "print(f\"R² Lasso (StandardScaler + Poly + CV): {r2_lasso_standart_scaler_poly_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + Poly + CV): {r2_lasso_min_max_scaler_poly_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'model': Ridge(), 'model__alpha': np.float64(29.763514416313132), 'poly__degree': 2, 'scaler': StandardScaler()}\n",
      "R2 лучшей модели: 0.8215\n",
      "Результаты всех моделей:\n",
      "                           model   task        R2\n",
      "0                             LR  task2  0.668483\n",
      "1                          Ridge  task2  0.665961\n",
      "2                          Lasso  task2  0.666869\n",
      "3             Ridge_GridSearchCV  task3  0.668483\n",
      "4                        RidgeCV  task3  0.668483\n",
      "5             Lasso_GridSearchCV  task3  0.668483\n",
      "6                        LassoCV  task3  0.668483\n",
      "7           Ridge_StandardScaler  task4  0.668190\n",
      "8             Ridge_MinMaxScaler  task4  0.676221\n",
      "9           Lasso_StandardScaler  task4  0.624045\n",
      "10            Lasso_MinMaxScaler  task4  0.257392\n",
      "11       Ridge_StandardScaler_CV  task5  0.667652\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13       Lasso_StandardScaler_CV  task5  0.668482\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15     Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17     Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.821513\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.849789\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.817555\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.849540\n",
      "23                    Best_Model  task8  0.821513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Настройка Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Масштабирование\n",
    "    ('poly', PolynomialFeatures()),  # Полиномиальные признаки\n",
    "    ('model', Ridge())  # Регрессия (пока по умолчанию)\n",
    "])\n",
    "\n",
    "# Настройка параметров для GridSearchCV\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'poly__degree': [1, 2],  # Степень полинома (без полинома, квадраты)\n",
    "    'model': [Ridge(), Lasso()],\n",
    "    'model__alpha': np.logspace(-4, 4, 20)  # Коэффициент регуляризации\n",
    "}\n",
    "\n",
    "# Настройка GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры и лучший результат\n",
    "best_params = grid_search.best_params_\n",
    "r2_best_model = r2_score(y_test, grid_search.best_estimator_.predict(X_test))\n",
    "\n",
    "# Запись результата в DataFrame\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]\n",
    "\n",
    "# Вывод результатов\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "print('R2 лучшей модели: {:.4f}'.format(r2_best_model))\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты всех моделей:\")\n",
    "print(results_regression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    37155\n",
      "0    11687\n",
      "Name: count, dtype: int64\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  \n",
      "0          2174             0              40  United-States  \n",
      "1             0             0              13  United-States  \n",
      "2             0             0              40  United-States  \n",
      "3             0             0              40  United-States  \n",
      "4             0             0              40           Cuba  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)  # Удаление колонки 'class' из признаков\n",
    "y = data['class']  # Сохранение колонки 'class' как целевой переменной\n",
    "\n",
    "# Замена целевой переменной на числовые значения ('<=50K' - 1, '>50K' - 0)\n",
    "y = y.map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Проверка результатов\n",
    "print(y.value_counts())  # Проверка распределения классов\n",
    "print(X.head())  # Просмотр первых 5 строк признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model    task      f1  accuracy\n",
      "0  Most Frequent class  task10  0.8641  0.760718\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})  # Преобразование целевой переменной\n",
    "\n",
    "# Определение самого частого класса\n",
    "most_frequent_class = y.mode()[0]\n",
    "\n",
    "# Предсказания с использованием самого частого класса\n",
    "y_pred_most_frequent = [most_frequent_class] * len(y)\n",
    "\n",
    "# Расчет метрик\n",
    "acc_most_frequent = accuracy_score(y, y_pred_most_frequent)\n",
    "f1_most_frequent = f1_score(y, y_pred_most_frequent)\n",
    "\n",
    "# Запись результата в DataFrame\n",
    "results_classification = pd.DataFrame(columns=['model', 'task', 'f1', 'accuracy'])\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в данных:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n",
      "Пропуски после заполнения:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Проверка наличия пропусков\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Пропуски в данных:\\n\", missing_values)\n",
    "\n",
    "# Если присутствуют пропуски, заполняем их самыми частыми значениями\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Проверка на наличие пропусков после заполнения\n",
    "missing_values_after_imputation = data_imputed.isnull().sum()\n",
    "print(\"Пропуски после заполнения:\\n\", missing_values_after_imputation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые колонки:\n",
      " Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "\n",
      "Категориальные колонки:\n",
      " Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Выбор числовых колонок\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Выбор категориальных колонок\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Вывод списков числовых и категориальных колонок\n",
    "print(\"Числовые колонки:\\n\", numeric_columns)\n",
    "print(\"\\nКатегориальные колонки:\\n\", categorical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model    task        f1  accuracy\n",
      "1    LogisticRegression  task13  0.904781  0.850825\n",
      "2  KNeighborsClassifier  task13  0.886981  0.824761\n",
      "3             LinearSVC  task13  0.906294  0.852873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выбор числовых и категориальных колонок\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Создание пайплайна для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Создание пайплайна для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединение всех трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Создание моделей\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Подсчет cross_val_score для каждой модели по метрикам accuracy и f1_score\n",
    "results_classification = pd.DataFrame(columns=['model', 'task', 'f1', 'accuracy'])\n",
    "\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    # Создание общего пайплайна\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Подсчет метрик через cross_val_score\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    \n",
    "    # Запись среднего значения метрик в results_classification\n",
    "    results_classification.loc[i + 1] = [model_name, 'task13', f1_scores.mean(), acc_scores.mean()]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\285\\AppData\\Local\\Temp\\ipykernel_10244\\3614646836.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: np.nan if pd.isna(x) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model task   f1 accuracy  LogisticRegression\n",
      "Accuracy   NaN  NaN  NaN      NaN            0.851378\n",
      "F1 Score   NaN  NaN  NaN      NaN            0.905127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Преобразование всех значений pandas.NA в np.nan\n",
    "X = X.applymap(lambda x: np.nan if pd.isna(x) else x)\n",
    "\n",
    "# Подготовка и обучение модели\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Пайплайн для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Пайплайн для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Объединение препроцессора и модели в один пайплайн\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "# Подсчет метрик через cross_val_score\n",
    "acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "\n",
    "# Запись среднего значения метрик\n",
    "results_classification['LogisticRegression'] = {\n",
    "    'Accuracy': np.mean(acc_scores),\n",
    "    'F1 Score': np.mean(f1_scores)\n",
    "}\n",
    "# Вывод результатов\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model    Task  F1 Score  Accuracy\n",
      "0    LogisticRegression_delete_missings  task15  0.902171  0.848569\n",
      "1  KNeighborsClassifier_delete_missings  task15  0.887012  0.827297\n",
      "2             LinearSVC_delete_missings  task15  0.902604  0.848835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Удаление строк с пропущенными значениями '?'\n",
    "X = X.replace('?', np.nan)\n",
    "X = X.dropna()\n",
    "\n",
    "# Обновление целевой переменной y, если были удалены строки из X\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Пайплайн для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Пайплайн для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Функция для подсчета метрик cross_val_score\n",
    "def calculate_metrics(model):\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    return np.mean(f1_scores), np.mean(acc_scores)\n",
    "\n",
    "# Модели для оценки\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC()\n",
    "}\n",
    "\n",
    "# Запись результатов в таблицу\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    f1_score_mean, acc_score_mean = calculate_metrics(model)\n",
    "    results_classification.loc[len(results_classification)] = [\n",
    "        f'{model_name}_delete_missings', 'task15', f1_score_mean, acc_score_mean]\n",
    "\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model    Task  F1 Score  Accuracy\n",
      "0      RandomForestClassifier  task16  0.901231  0.848945\n",
      "1  GradientBoostingClassifier  task16  0.912227  0.862921\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Замена значений '?' на NaN\n",
    "X = X.replace('?', np.nan)\n",
    "\n",
    "# Импутер для замены NaN на самые частые значения\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Применение импутора к числовым и категориальным данным\n",
    "X[numeric_features] = most_frequent_imputer.fit_transform(X[numeric_features])\n",
    "X[categorical_features] = most_frequent_imputer.fit_transform(X[categorical_features])\n",
    "\n",
    "# Обновление целевой переменной y, если были удалены строки из X\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Функция для подсчета метрик cross_val_score\n",
    "def calculate_metrics(model):\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    return np.mean(f1_scores), np.mean(acc_scores)\n",
    "\n",
    "# Модели для оценки\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Запись результатов в таблицу\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    f1_score_mean, acc_score_mean = calculate_metrics(model)\n",
    "    results_classification.loc[len(results_classification)] = [\n",
    "        model_name, 'task16', f1_score_mean, acc_score_mean]\n",
    "\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "# Подготовка данных\n",
    "X = X.replace('?', np.nan)  # Заменяем '?' на np.nan\n",
    "\n",
    "# Определение признаков\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Определение пайплайнов для числовых и категориальных данных\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Определение ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Определение моделей\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'preprocessor__num__scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'preprocessor__cat__imputer__strategy': ['most_frequent', 'constant'],\n",
    "    'preprocessor__cat__onehot__handle_unknown': ['ignore', 'error']\n",
    "}\n",
    "\n",
    "# Инициализация переменных для хранения лучших результатов\n",
    "best_params = {}\n",
    "f1_best = 0\n",
    "acc_best = 0\n",
    "\n",
    "# Инициализация DataFrame для результатов\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "# Подбор модели и параметров\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring={'accuracy': make_scorer(accuracy_score), 'f1': make_scorer(f1_score)},\n",
    "        refit='f1',  # Используем f1 для выбора лучшей модели\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    f1_score_mean = grid_search.best_score_\n",
    "    acc_score_mean = cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='accuracy').mean()\n",
    "    \n",
    "    if f1_score_mean > f1_best:\n",
    "        f1_best = f1_score_mean\n",
    "        acc_best = acc_score_mean\n",
    "        results_classification = results_classification.append({\n",
    "            'Model': model_name,\n",
    "            'Task': 'task17',\n",
    "            'F1 Score': f1_best,\n",
    "            'Accuracy': acc_best\n",
    "        }, ignore_index=True)\n",
    "\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
