{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (404, 13)\n",
      "Размер тестовой выборки: (102, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Выделение целевой переменной и признаков\n",
    "X = data.drop(columns=['MEDV'])\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Проверка размеров полученных выборок\n",
    "print(\"Размер обучающей выборки:\", X_train.shape)\n",
    "print(\"Размер тестовой выборки:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   model   task        R2\n",
      "0     LR  task2  0.668483\n",
      "1  Ridge  task2  0.665961\n",
      "2  Lasso  task2  0.666869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Создание и обучение моделей\n",
    "lr_model = LinearRegression()\n",
    "ridge_model = Ridge(random_state=RANDOM_STATE)\n",
    "lasso_model = Lasso(random_state=RANDOM_STATE)\n",
    "\n",
    "# Обучение моделей\n",
    "lr_model.fit(X_train, y_train)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Вычисление R² для каждой модели\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[0] = ['LR', 'task2', r2_lr]\n",
    "results_regression.loc[1] = ['Ridge', 'task2', r2_ridge]\n",
    "results_regression.loc[2] = ['Lasso', 'task2', r2_lasso]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_regression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты для задания 2 и 3:\n",
      "                model   task        R2\n",
      "0                  LR  task2  0.668483\n",
      "1               Ridge  task2  0.665961\n",
      "2               Lasso  task2  0.666869\n",
      "3  Ridge_GridSearchCV  task3  0.668483\n",
      "4             RidgeCV  task3  0.668483\n",
      "5  Lasso_GridSearchCV  task3  0.668483\n",
      "6             LassoCV  task3  0.668483\n",
      "\n",
      "Сравнение с результатами из задания 2:\n",
      "Ridge (GridSearchCV) улучшение R²: 0.0025\n",
      "Ridge (RidgeCV) улучшение R²: 0.0025\n",
      "Lasso (GridSearchCV) улучшение R²: 0.0016\n",
      "Lasso (LassoCV) улучшение R²: 0.0016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Задание диапазона параметров для регуляризации (по степеням 10)\n",
    "alphas = np.logspace(-5, 5, 100)\n",
    "\n",
    "# GridSearchCV для Ridge\n",
    "ridge_grid_search = GridSearchCV(Ridge(random_state=RANDOM_STATE), \n",
    "                                 param_grid={'alpha': alphas}, \n",
    "                                 cv=5, \n",
    "                                 scoring='r2')\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "r2_ridge_grid_search = r2_score(y_test, ridge_grid_search.predict(X_test))\n",
    "\n",
    "# RidgeCV\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "r2_ridge_cv = r2_score(y_test, ridge_cv.predict(X_test))\n",
    "\n",
    "# GridSearchCV для Lasso\n",
    "lasso_grid_search = GridSearchCV(Lasso(random_state=RANDOM_STATE), \n",
    "                                 param_grid={'alpha': alphas}, \n",
    "                                 cv=5, \n",
    "                                 scoring='r2')\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "r2_lasso_grid_search = r2_score(y_test, lasso_grid_search.predict(X_test))\n",
    "\n",
    "# LassoCV\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "r2_lasso_cv = r2_score(y_test, lasso_cv.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[3] = ['Ridge_GridSearchCV', 'task3', r2_ridge_grid_search]\n",
    "results_regression.loc[4] = ['RidgeCV', 'task3', r2_ridge_cv]\n",
    "results_regression.loc[5] = ['Lasso_GridSearchCV', 'task3', r2_lasso_grid_search]\n",
    "results_regression.loc[6] = ['LassoCV', 'task3', r2_lasso_cv]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Результаты для задания 2 и 3:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение с результатами из задания 2\n",
    "improvement_ridge_grid_search = r2_ridge_grid_search - results_regression.loc[1, 'R2']\n",
    "improvement_ridge_cv = r2_ridge_cv - results_regression.loc[1, 'R2']\n",
    "improvement_lasso_grid_search = r2_lasso_grid_search - results_regression.loc[2, 'R2']\n",
    "improvement_lasso_cv = r2_lasso_cv - results_regression.loc[2, 'R2']\n",
    "\n",
    "print(\"\\nСравнение с результатами из задания 2:\")\n",
    "print(f\"Ridge (GridSearchCV) улучшение R²: {improvement_ridge_grid_search:.4f}\")\n",
    "print(f\"Ridge (RidgeCV) улучшение R²: {improvement_ridge_cv:.4f}\")\n",
    "print(f\"Lasso (GridSearchCV) улучшение R²: {improvement_lasso_grid_search:.4f}\")\n",
    "print(f\"Lasso (LassoCV) улучшение R²: {improvement_lasso_cv:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3 и 4:\n",
      "                   model   task        R2\n",
      "0                     LR  task2  0.668483\n",
      "1                  Ridge  task2  0.665961\n",
      "2                  Lasso  task2  0.666869\n",
      "3     Ridge_GridSearchCV  task3  0.668483\n",
      "4                RidgeCV  task3  0.668483\n",
      "5     Lasso_GridSearchCV  task3  0.668483\n",
      "6                LassoCV  task3  0.668483\n",
      "7   Ridge_StandardScaler  task4  0.668190\n",
      "8     Ridge_MinMaxScaler  task4  0.676221\n",
      "9   Lasso_StandardScaler  task4  0.624045\n",
      "10    Lasso_MinMaxScaler  task4  0.257392\n",
      "\n",
      "Сравнение R² моделей из задания 4 с моделями из заданий 2 и 3:\n",
      "R² Ridge (StandardScaler): 0.6682 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler): 0.6762 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler): 0.6240 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler): 0.2574 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler\n",
    "ridge_standard_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_standard_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler = r2_score(y_test, ridge_standard_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler\n",
    "ridge_minmax_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_minmax_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler = r2_score(y_test, ridge_minmax_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler\n",
    "lasso_standard_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler = r2_score(y_test, lasso_standard_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler\n",
    "lasso_minmax_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler = r2_score(y_test, lasso_minmax_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[7] = ['Ridge_StandardScaler', 'task4', r2_ridge_standart_scaler]\n",
    "results_regression.loc[8] = ['Ridge_MinMaxScaler', 'task4', r2_ridge_min_max_scaler]\n",
    "results_regression.loc[9] = ['Lasso_StandardScaler', 'task4', r2_lasso_standart_scaler]\n",
    "results_regression.loc[10] = ['Lasso_MinMaxScaler', 'task4', r2_lasso_min_max_scaler]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3 и 4:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 4 с моделями из заданий 2 и 3:\")\n",
    "\n",
    "# Сравнение Ridge с StandardScaler и MinMaxScaler и базовыми результатами\n",
    "print(f\"R² Ridge (StandardScaler): {r2_ridge_standart_scaler:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler): {r2_ridge_min_max_scaler:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение Lasso с StandardScaler и MinMaxScaler и базовыми результатами\n",
    "print(f\"R² Lasso (StandardScaler): {r2_lasso_standart_scaler:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler): {r2_lasso_min_max_scaler:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4 и 5:\n",
      "                      model   task        R2\n",
      "0                        LR  task2  0.668483\n",
      "1                     Ridge  task2  0.665961\n",
      "2                     Lasso  task2  0.666869\n",
      "3        Ridge_GridSearchCV  task3  0.668483\n",
      "4                   RidgeCV  task3  0.668483\n",
      "5        Lasso_GridSearchCV  task3  0.668483\n",
      "6                   LassoCV  task3  0.668483\n",
      "7      Ridge_StandardScaler  task4  0.668190\n",
      "8        Ridge_MinMaxScaler  task4  0.676221\n",
      "9      Lasso_StandardScaler  task4  0.624045\n",
      "10       Lasso_MinMaxScaler  task4  0.257392\n",
      "11  Ridge_StandardScaler_CV  task5  0.667652\n",
      "12    Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13  Lasso_StandardScaler_CV  task5  0.668482\n",
      "14    Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "\n",
      "Сравнение R² моделей из задания 5 с моделями из заданий 2, 3 и 4:\n",
      "R² Ridge (StandardScaler + CV): 0.6677 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + CV): 0.6717 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + CV): 0.6685 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + CV): 0.6685 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "# RidgeCV на данных с StandardScaler\n",
    "ridge_standard_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_standard_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_cv = r2_score(y_test, ridge_standard_cv_pipeline.predict(X_test))\n",
    "\n",
    "# RidgeCV на данных с MinMaxScaler\n",
    "ridge_minmax_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_minmax_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_cv = r2_score(y_test, ridge_minmax_cv_pipeline.predict(X_test))\n",
    "\n",
    "# LassoCV на данных с StandardScaler\n",
    "lasso_standard_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_cv = r2_score(y_test, lasso_standard_cv_pipeline.predict(X_test))\n",
    "\n",
    "# LassoCV на данных с MinMaxScaler\n",
    "lasso_minmax_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_cv = r2_score(y_test, lasso_minmax_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[11] = ['Ridge_StandardScaler_CV', 'task5', r2_ridge_standart_scaler_cv]\n",
    "results_regression.loc[12] = ['Ridge_MinMaxScaler_CV', 'task5', r2_ridge_min_max_scaler_cv]\n",
    "results_regression.loc[13] = ['Lasso_StandardScaler_CV', 'task5', r2_lasso_standart_scaler_cv]\n",
    "results_regression.loc[14] = ['Lasso_MinMaxScaler_CV', 'task5', r2_lasso_min_max_scaler_cv]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4 и 5:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 5 с моделями из заданий 2, 3 и 4:\")\n",
    "\n",
    "# Сравнение RidgeCV на масштабированных данных с результатами из заданий 2, 3 и 4\n",
    "print(f\"R² Ridge (StandardScaler + CV): {r2_ridge_standart_scaler_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + CV): {r2_ridge_min_max_scaler_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение LassoCV на масштабированных данных с результатами из заданий 2, 3 и 4\n",
    "print(f\"R² Lasso (StandardScaler + CV): {r2_lasso_standart_scaler_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + CV): {r2_lasso_min_max_scaler_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4, 5 и 6:\n",
      "                        model   task        R2\n",
      "0                          LR  task2  0.668483\n",
      "1                       Ridge  task2  0.665961\n",
      "2                       Lasso  task2  0.666869\n",
      "3          Ridge_GridSearchCV  task3  0.668483\n",
      "4                     RidgeCV  task3  0.668483\n",
      "5          Lasso_GridSearchCV  task3  0.668483\n",
      "6                     LassoCV  task3  0.668483\n",
      "7        Ridge_StandardScaler  task4  0.668190\n",
      "8          Ridge_MinMaxScaler  task4  0.676221\n",
      "9        Lasso_StandardScaler  task4  0.624045\n",
      "10         Lasso_MinMaxScaler  task4  0.257392\n",
      "11    Ridge_StandardScaler_CV  task5  0.667652\n",
      "12      Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13    Lasso_StandardScaler_CV  task5  0.668482\n",
      "14      Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15  Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16    Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17  Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18    Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "\n",
      "Сравнение R² моделей из задания 6 с моделями из заданий 2, 3, 4 и 5:\n",
      "R² Ridge (StandardScaler + Poly): 0.8171 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + Poly): 0.8299 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + Poly): 0.7323 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + Poly): 0.2611 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Создание PolynomialFeatures (попарные произведения признаков и их квадраты)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler и PolynomialFeatures\n",
    "ridge_standard_poly_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_standard_poly_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_poly = r2_score(y_test, ridge_standard_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler и PolynomialFeatures\n",
    "ridge_minmax_poly_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Ridge(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "ridge_minmax_poly_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_poly = r2_score(y_test, ridge_minmax_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler и PolynomialFeatures\n",
    "lasso_standard_poly_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_standard_poly_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_poly = r2_score(y_test, lasso_standard_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler и PolynomialFeatures\n",
    "lasso_minmax_poly_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', Lasso(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "lasso_minmax_poly_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_poly = r2_score(y_test, lasso_minmax_poly_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[15] = ['Ridge_StandardScaler_Poly', 'task6', r2_ridge_standart_scaler_poly]\n",
    "results_regression.loc[16] = ['Ridge_MinMaxScaler_Poly', 'task6', r2_ridge_min_max_scaler_poly]\n",
    "results_regression.loc[17] = ['Lasso_StandardScaler_Poly', 'task6', r2_lasso_standart_scaler_poly]\n",
    "results_regression.loc[18] = ['Lasso_MinMaxScaler_Poly', 'task6', r2_lasso_min_max_scaler_poly]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4, 5 и 6:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 6 с моделями из заданий 2, 3, 4 и 5:\")\n",
    "\n",
    "# Сравнение Ridge с PolynomialFeatures на данных, прошедших через StandardScaler и MinMaxScaler, с результатами из заданий 2, 3, 4 и 5\n",
    "print(f\"R² Ridge (StandardScaler + Poly): {r2_ridge_standart_scaler_poly:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + Poly): {r2_ridge_min_max_scaler_poly:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение Lasso с PolynomialFeatures на данных, прошедших через StandardScaler и MinMaxScaler, с результатами из заданий 2, 3, 4 и 5\n",
    "print(f\"R² Lasso (StandardScaler + Poly): {r2_lasso_standart_scaler_poly:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + Poly): {r2_lasso_min_max_scaler_poly:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.481217564566123, tolerance: 2.764448730650155\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.912554424862719, tolerance: 2.710494922600619\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.65145301711209, tolerance: 2.7297569226006195\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.547071195946501, tolerance: 2.947695024691358\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты моделей из заданий 2, 3, 4, 5, 6 и 7:\n",
      "                           model   task        R2\n",
      "0                             LR  task2  0.668483\n",
      "1                          Ridge  task2  0.665961\n",
      "2                          Lasso  task2  0.666869\n",
      "3             Ridge_GridSearchCV  task3  0.668483\n",
      "4                        RidgeCV  task3  0.668483\n",
      "5             Lasso_GridSearchCV  task3  0.668483\n",
      "6                        LassoCV  task3  0.668483\n",
      "7           Ridge_StandardScaler  task4  0.668190\n",
      "8             Ridge_MinMaxScaler  task4  0.676221\n",
      "9           Lasso_StandardScaler  task4  0.624045\n",
      "10            Lasso_MinMaxScaler  task4  0.257392\n",
      "11       Ridge_StandardScaler_CV  task5  0.667652\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13       Lasso_StandardScaler_CV  task5  0.668482\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15     Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17     Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.821513\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.849789\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.817555\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.849540\n",
      "\n",
      "Сравнение R² моделей из задания 7 с моделями из заданий 2, 3, 4, 5 и 6:\n",
      "R² Ridge (StandardScaler + Poly + CV): 0.8215 | R² Ridge (задание 2): 0.6660\n",
      "R² Ridge (MinMaxScaler + Poly + CV): 0.8498 | R² Ridge (задание 2): 0.6660\n",
      "R² Lasso (StandardScaler + Poly + CV): 0.8176 | R² Lasso (задание 2): 0.6669\n",
      "R² Lasso (MinMaxScaler + Poly + CV): 0.8495 | R² Lasso (задание 2): 0.6669\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Альтернативные значения коэффициентов регуляризации\n",
    "alphas = np.logspace(-4, 4, 20)  # Увеличение диапазона для более тщательного поиска\n",
    "\n",
    "# PolynomialFeatures (попарные произведения признаков и их квадраты)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Pipeline для Ridge с StandardScaler, PolynomialFeatures и RidgeCV\n",
    "ridge_standard_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_standard_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_standart_scaler_poly_cv = r2_score(y_test, ridge_standard_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Ridge с MinMaxScaler, PolynomialFeatures и RidgeCV\n",
    "ridge_minmax_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "ridge_minmax_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_ridge_min_max_scaler_poly_cv = r2_score(y_test, ridge_minmax_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с StandardScaler, PolynomialFeatures и LassoCV\n",
    "lasso_standard_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, max_iter=200000, tol=1e-4, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_standard_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_standart_scaler_poly_cv = r2_score(y_test, lasso_standard_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Pipeline для Lasso с MinMaxScaler, PolynomialFeatures и LassoCV\n",
    "lasso_minmax_poly_cv_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('poly', poly),\n",
    "    ('model', LassoCV(alphas=alphas, cv=5, max_iter=200000, tol=1e-4, random_state=42))\n",
    "])\n",
    "\n",
    "lasso_minmax_poly_cv_pipeline.fit(X_train, y_train)\n",
    "r2_lasso_min_max_scaler_poly_cv = r2_score(y_test, lasso_minmax_poly_cv_pipeline.predict(X_test))\n",
    "\n",
    "# Запись результатов в DataFrame\n",
    "results_regression.loc[19] = ['Ridge_StandardScaler_Poly_CV', 'task7', r2_ridge_standart_scaler_poly_cv]\n",
    "results_regression.loc[20] = ['Ridge_MinMaxScaler_Poly_CV', 'task7', r2_ridge_min_max_scaler_poly_cv]\n",
    "results_regression.loc[21] = ['Lasso_StandardScaler_Poly_CV', 'task7', r2_lasso_standart_scaler_poly_cv]\n",
    "results_regression.loc[22] = ['Lasso_MinMaxScaler_Poly_CV', 'task7', r2_lasso_min_max_scaler_poly_cv]\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты моделей из заданий 2, 3, 4, 5, 6 и 7:\")\n",
    "print(results_regression)\n",
    "\n",
    "# Сравнение результатов\n",
    "print(\"\\nСравнение R² моделей из задания 7 с моделями из заданий 2, 3, 4, 5 и 6:\")\n",
    "\n",
    "# Сравнение RidgeCV с PolynomialFeatures и масштабированием с результатами из заданий 2, 3, 4, 5 и 6\n",
    "print(f\"R² Ridge (StandardScaler + Poly + CV): {r2_ridge_standart_scaler_poly_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "print(f\"R² Ridge (MinMaxScaler + Poly + CV): {r2_ridge_min_max_scaler_poly_cv:.4f} | R² Ridge (задание 2): {results_regression.loc[1, 'R2']:.4f}\")\n",
    "\n",
    "# Сравнение LassoCV с PolynomialFeatures и масштабированием с результатами из заданий 2, 3, 4, 5 и 6\n",
    "print(f\"R² Lasso (StandardScaler + Poly + CV): {r2_lasso_standart_scaler_poly_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n",
    "print(f\"R² Lasso (MinMaxScaler + Poly + CV): {r2_lasso_min_max_scaler_poly_cv:.4f} | R² Lasso (задание 2): {results_regression.loc[2, 'R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'model': Ridge(), 'model__alpha': np.float64(29.763514416313132), 'poly__degree': 2, 'scaler': StandardScaler()}\n",
      "R2 лучшей модели: 0.8215\n",
      "Результаты всех моделей:\n",
      "                           model   task        R2\n",
      "0                             LR  task2  0.668483\n",
      "1                          Ridge  task2  0.665961\n",
      "2                          Lasso  task2  0.666869\n",
      "3             Ridge_GridSearchCV  task3  0.668483\n",
      "4                        RidgeCV  task3  0.668483\n",
      "5             Lasso_GridSearchCV  task3  0.668483\n",
      "6                        LassoCV  task3  0.668483\n",
      "7           Ridge_StandardScaler  task4  0.668190\n",
      "8             Ridge_MinMaxScaler  task4  0.676221\n",
      "9           Lasso_StandardScaler  task4  0.624045\n",
      "10            Lasso_MinMaxScaler  task4  0.257392\n",
      "11       Ridge_StandardScaler_CV  task5  0.667652\n",
      "12         Ridge_MinMaxScaler_CV  task5  0.671688\n",
      "13       Lasso_StandardScaler_CV  task5  0.668482\n",
      "14         Lasso_MinMaxScaler_CV  task5  0.668484\n",
      "15     Ridge_StandardScaler_Poly  task6  0.817136\n",
      "16       Ridge_MinMaxScaler_Poly  task6  0.829886\n",
      "17     Lasso_StandardScaler_Poly  task6  0.732274\n",
      "18       Lasso_MinMaxScaler_Poly  task6  0.261126\n",
      "19  Ridge_StandardScaler_Poly_CV  task7  0.821513\n",
      "20    Ridge_MinMaxScaler_Poly_CV  task7  0.849789\n",
      "21  Lasso_StandardScaler_Poly_CV  task7  0.817555\n",
      "22    Lasso_MinMaxScaler_Poly_CV  task7  0.849540\n",
      "23                    Best_Model  task8  0.821513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('boston.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "X = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Настройка Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Масштабирование\n",
    "    ('poly', PolynomialFeatures()),  # Полиномиальные признаки\n",
    "    ('model', Ridge())  # Регрессия (пока по умолчанию)\n",
    "])\n",
    "\n",
    "# Настройка параметров для GridSearchCV\n",
    "param_grid = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'poly__degree': [1, 2],  # Степень полинома (без полинома, квадраты)\n",
    "    'model': [Ridge(), Lasso()],\n",
    "    'model__alpha': np.logspace(-4, 4, 20)  # Коэффициент регуляризации\n",
    "}\n",
    "\n",
    "# Настройка GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры и лучший результат\n",
    "best_params = grid_search.best_params_\n",
    "r2_best_model = r2_score(y_test, grid_search.best_estimator_.predict(X_test))\n",
    "\n",
    "# Запись результата в DataFrame\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]\n",
    "\n",
    "# Вывод результатов\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "print('R2 лучшей модели: {:.4f}'.format(r2_best_model))\n",
    "\n",
    "# Вывод всех результатов\n",
    "print(\"Результаты всех моделей:\")\n",
    "print(results_regression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.665961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.666869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso_GridSearchCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>task3</td>\n",
       "      <td>0.668483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.668190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.676221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso_StandardScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.624045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso_MinMaxScaler</td>\n",
       "      <td>task4</td>\n",
       "      <td>0.257392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.667652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.671688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso_StandardScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.668482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso_MinMaxScaler_CV</td>\n",
       "      <td>task5</td>\n",
       "      <td>0.668484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.817136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.829886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lasso_StandardScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.732274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly</td>\n",
       "      <td>task6</td>\n",
       "      <td>0.261126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ridge_StandardScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.821513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ridge_MinMaxScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.849789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lasso_StandardScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.817555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lasso_MinMaxScaler_Poly_CV</td>\n",
       "      <td>task7</td>\n",
       "      <td>0.849540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Best_Model</td>\n",
       "      <td>task8</td>\n",
       "      <td>0.821513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model   task        R2\n",
       "0                             LR  task2  0.668483\n",
       "1                          Ridge  task2  0.665961\n",
       "2                          Lasso  task2  0.666869\n",
       "3             Ridge_GridSearchCV  task3  0.668483\n",
       "4                        RidgeCV  task3  0.668483\n",
       "5             Lasso_GridSearchCV  task3  0.668483\n",
       "6                        LassoCV  task3  0.668483\n",
       "7           Ridge_StandardScaler  task4  0.668190\n",
       "8             Ridge_MinMaxScaler  task4  0.676221\n",
       "9           Lasso_StandardScaler  task4  0.624045\n",
       "10            Lasso_MinMaxScaler  task4  0.257392\n",
       "11       Ridge_StandardScaler_CV  task5  0.667652\n",
       "12         Ridge_MinMaxScaler_CV  task5  0.671688\n",
       "13       Lasso_StandardScaler_CV  task5  0.668482\n",
       "14         Lasso_MinMaxScaler_CV  task5  0.668484\n",
       "15     Ridge_StandardScaler_Poly  task6  0.817136\n",
       "16       Ridge_MinMaxScaler_Poly  task6  0.829886\n",
       "17     Lasso_StandardScaler_Poly  task6  0.732274\n",
       "18       Lasso_MinMaxScaler_Poly  task6  0.261126\n",
       "19  Ridge_StandardScaler_Poly_CV  task7  0.821513\n",
       "20    Ridge_MinMaxScaler_Poly_CV  task7  0.849789\n",
       "21  Lasso_StandardScaler_Poly_CV  task7  0.817555\n",
       "22    Lasso_MinMaxScaler_Poly_CV  task7  0.849540\n",
       "23                    Best_Model  task8  0.821513"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('adult.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1    37155\n",
      "0    11687\n",
      "Name: count, dtype: int64\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  \n",
      "0          2174             0              40  United-States  \n",
      "1             0             0              13  United-States  \n",
      "2             0             0              40  United-States  \n",
      "3             0             0              40  United-States  \n",
      "4             0             0              40           Cuba  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)  # Удаление колонки 'class' из признаков\n",
    "y = data['class']  # Сохранение колонки 'class' как целевой переменной\n",
    "\n",
    "# Замена целевой переменной на числовые значения ('<=50K' - 1, '>50K' - 0)\n",
    "y = y.map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Проверка результатов\n",
    "print(y.value_counts())  # Проверка распределения классов\n",
    "print(X.head())  # Просмотр первых 5 строк признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model    task      f1  accuracy\n",
      "0  Most Frequent class  task10  0.8641  0.760718\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})  # Преобразование целевой переменной\n",
    "\n",
    "# Определение самого частого класса\n",
    "most_frequent_class = y.mode()[0]\n",
    "\n",
    "# Предсказания с использованием самого частого класса\n",
    "y_pred_most_frequent = [most_frequent_class] * len(y)\n",
    "\n",
    "# Расчет метрик\n",
    "acc_most_frequent = accuracy_score(y, y_pred_most_frequent)\n",
    "f1_most_frequent = f1_score(y, y_pred_most_frequent)\n",
    "\n",
    "# Запись результата в DataFrame\n",
    "results_classification = pd.DataFrame(columns=['model', 'task', 'f1', 'accuracy'])\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в данных:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n",
      "Пропуски после заполнения:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Проверка наличия пропусков\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Пропуски в данных:\\n\", missing_values)\n",
    "\n",
    "# Если присутствуют пропуски, заполняем их самыми частыми значениями\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# Проверка на наличие пропусков после заполнения\n",
    "missing_values_after_imputation = data_imputed.isnull().sum()\n",
    "print(\"Пропуски после заполнения:\\n\", missing_values_after_imputation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые колонки:\n",
      " Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "\n",
      "Категориальные колонки:\n",
      " Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Выбор числовых колонок\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Выбор категориальных колонок\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Вывод списков числовых и категориальных колонок\n",
    "print(\"Числовые колонки:\\n\", numeric_columns)\n",
    "print(\"\\nКатегориальные колонки:\\n\", categorical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model    task        f1  accuracy\n",
      "1    LogisticRegression  task13  0.904781  0.850825\n",
      "2  KNeighborsClassifier  task13  0.886981  0.824761\n",
      "3             LinearSVC  task13  0.906294  0.852873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('adult.csv')\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class'].map({'<=50K': 1, '>50K': 0})\n",
    "\n",
    "# Выбор числовых и категориальных колонок\n",
    "numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Создание пайплайна для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Создание пайплайна для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Объединение всех трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Создание моделей\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000)\n",
    "}\n",
    "\n",
    "# Подсчет cross_val_score для каждой модели по метрикам accuracy и f1_score\n",
    "results_classification = pd.DataFrame(columns=['model', 'task', 'f1', 'accuracy'])\n",
    "\n",
    "for i, (model_name, model) in enumerate(models.items()):\n",
    "    # Создание общего пайплайна\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    # Подсчет метрик через cross_val_score\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    \n",
    "    # Запись среднего значения метрик в results_classification\n",
    "    results_classification.loc[i + 1] = [model_name, 'task13', f1_scores.mean(), acc_scores.mean()]\n",
    "\n",
    "# Вывод результатов\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\285\\AppData\\Local\\Temp\\ipykernel_9576\\3614646836.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: np.nan if pd.isna(x) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model    task        f1  accuracy  LogisticRegression\n",
      "1    LogisticRegression  task13  0.904781  0.850825                 NaN\n",
      "2  KNeighborsClassifier  task13  0.886981  0.824761                 NaN\n",
      "3             LinearSVC  task13  0.906294  0.852873                 NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Преобразование всех значений pandas.NA в np.nan\n",
    "X = X.applymap(lambda x: np.nan if pd.isna(x) else x)\n",
    "\n",
    "# Подготовка и обучение модели\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Пайплайн для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Пайплайн для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Объединение препроцессора и модели в один пайплайн\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "# Подсчет метрик через cross_val_score\n",
    "acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "\n",
    "# Запись среднего значения метрик\n",
    "results_classification['LogisticRegression'] = {\n",
    "    'Accuracy': np.mean(acc_scores),\n",
    "    'F1 Score': np.mean(f1_scores)\n",
    "}\n",
    "# Вывод результатов\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model    Task  F1 Score  Accuracy\n",
      "0    LogisticRegression_delete_missings  task15  0.902171  0.848569\n",
      "1  KNeighborsClassifier_delete_missings  task15  0.887012  0.827297\n",
      "2             LinearSVC_delete_missings  task15  0.902604  0.848835\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Удаление строк с пропущенными значениями '?'\n",
    "X = X.replace('?', np.nan)\n",
    "X = X.dropna()\n",
    "\n",
    "# Обновление целевой переменной y, если были удалены строки из X\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Пайплайн для числовых данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Пайплайн для категориальных данных\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Функция для подсчета метрик cross_val_score\n",
    "def calculate_metrics(model):\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    return np.mean(f1_scores), np.mean(acc_scores)\n",
    "\n",
    "# Модели для оценки\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'LinearSVC': LinearSVC()\n",
    "}\n",
    "\n",
    "# Запись результатов в таблицу\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    f1_score_mean, acc_score_mean = calculate_metrics(model)\n",
    "    results_classification.loc[len(results_classification)] = [\n",
    "        f'{model_name}_delete_missings', 'task15', f1_score_mean, acc_score_mean]\n",
    "\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Model    Task  F1 Score  Accuracy\n",
      "0      RandomForestClassifier  task16  0.901211  0.848215\n",
      "1  GradientBoostingClassifier  task16  0.912224  0.862899\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Замена значений '?' на NaN\n",
    "X = X.replace('?', np.nan)\n",
    "\n",
    "# Импутер для замены NaN на самые частые значения\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Применение импутора к числовым и категориальным данным\n",
    "X[numeric_features] = most_frequent_imputer.fit_transform(X[numeric_features])\n",
    "X[categorical_features] = most_frequent_imputer.fit_transform(X[categorical_features])\n",
    "\n",
    "# Обновление целевой переменной y, если были удалены строки из X\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Определение трансформеров для числовых и категориальных данных\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Объединение трансформеров в ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Функция для подсчета метрик cross_val_score\n",
    "def calculate_metrics(model):\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    acc_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(accuracy_score))\n",
    "    f1_scores = cross_val_score(clf, X, y, cv=5, scoring=make_scorer(f1_score))\n",
    "    return np.mean(f1_scores), np.mean(acc_scores)\n",
    "\n",
    "# Модели для оценки\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Запись результатов в таблицу\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    f1_score_mean, acc_score_mean = calculate_metrics(model)\n",
    "    results_classification.loc[len(results_classification)] = [\n",
    "        model_name, 'task16', f1_score_mean, acc_score_mean]\n",
    "\n",
    "print(results_classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.84810492 0.84710987 0.84898944 0.84768484 0.84921058 0.84790591\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84799437 0.84887889 0.84797227 0.8483482  0.84848088 0.84823761\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.90102137 0.90045237 0.90163053 0.90082046 0.90176079 0.90091413\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.90092    0.90158006 0.90093911 0.9012535  0.90129917 0.90117761\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\285\\AppData\\Local\\Temp\\ipykernel_9576\\2390753215.py:81: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_classification = pd.concat([results_classification, pd.DataFrame({\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.86289872 0.86292084 0.86294295 0.86292084 0.86287661 0.86294295\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86287661 0.86292084 0.86289872 0.86289872 0.86287661 0.86289872\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\285\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.91222415 0.91223946 0.91225239 0.91223947 0.91221123 0.91225239\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91221123 0.91223947 0.91222655 0.91222655 0.91221123 0.91222655\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'RandomForestClassifier': {'preprocessor__cat__imputer__strategy': 'most_frequent', 'preprocessor__cat__onehot__handle_unknown': 'ignore', 'preprocessor__num__imputer__strategy': 'most_frequent', 'preprocessor__num__scaler': StandardScaler()}, 'GradientBoostingClassifier': {'preprocessor__cat__imputer__strategy': 'most_frequent', 'preprocessor__cat__onehot__handle_unknown': 'ignore', 'preprocessor__num__imputer__strategy': 'median', 'preprocessor__num__scaler': StandardScaler()}}\n",
      "                        Model    Task  F1 Score  Accuracy\n",
      "0      RandomForestClassifier  task17  0.901761  0.849299\n",
      "1  GradientBoostingClassifier  task17  0.912252  0.862943\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "# Подготовка данных\n",
    "X = X.replace('?', np.nan)  # Заменяем '?' на np.nan\n",
    "\n",
    "# Определение признаков\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Определение пайплайнов для числовых и категориальных данных\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Определение ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Определение моделей\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Определение параметров для GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'preprocessor__num__scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'preprocessor__cat__imputer__strategy': ['most_frequent', 'constant'],\n",
    "    'preprocessor__cat__onehot__handle_unknown': ['ignore', 'error']\n",
    "}\n",
    "\n",
    "# Инициализация переменных для хранения лучших результатов\n",
    "best_params = {}\n",
    "f1_best = 0\n",
    "acc_best = 0\n",
    "\n",
    "# Инициализация DataFrame для результатов\n",
    "results_classification = pd.DataFrame(columns=['Model', 'Task', 'F1 Score', 'Accuracy'])\n",
    "\n",
    "# Подбор модели и параметров\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring={'accuracy': make_scorer(accuracy_score), 'f1': make_scorer(f1_score)},\n",
    "        refit='f1',  # Используем f1 для выбора лучшей модели\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    f1_score_mean = grid_search.best_score_\n",
    "    acc_score_mean = cross_val_score(grid_search.best_estimator_, X, y, cv=5, scoring='accuracy').mean()\n",
    "    \n",
    "    if f1_score_mean > f1_best:\n",
    "        f1_best = f1_score_mean\n",
    "        acc_best = acc_score_mean\n",
    "        results_classification = pd.concat([results_classification, pd.DataFrame({\n",
    "            'Model': [model_name],\n",
    "            'Task': ['task17'],\n",
    "            'F1 Score': [f1_best],\n",
    "            'Accuracy': [acc_best]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "print(results_classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
